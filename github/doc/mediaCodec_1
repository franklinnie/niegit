MediaCodec类可以访问底层媒体编解码器框架（StageFright或openMAX）,即编码器/解码器组件。
这是Android low-level多媒体支持基础设施的一部分
(通常与MediaExtractor, MediaSync, MediaMuxer, MediaCrypto, MediaDrm, Image, Surface, and AudioTrack.一起使用))。 

mAudioEncoder.start();
mAudioInputBuffers = mAudioEncoder.getInputBuffers();
mAudioOutputBuffers = mAudioEncoder.getOutputBuffers();

int inputBufIndex = mAudioEncoder.dequeueInputBuffer(1000);

mInputBuffer = mAudioInputBuffers[inputBufIndex];
mInputBuffer.clear();



mInputBuffer.put(bytes, 0, BUFFER_SIZE_IN_BYTES);
mAudioEncoder.queueInputBuffer(inputBufIndex, 0, BUFFER_SIZE_IN_BYTES, (1000000 * mEncodedSize / AUDIO_BYTE_PER_SAMPLE), 0);

int outputBufIndex = mAudioEncoder.dequeueOutputBuffer(mOutBufferInfo, 1000);

mOutBuffer = mAudioOutputBuffers[outputBufIndex];
if ((mOutBufferInfo.flags & MediaCodec.BUFFER_FLAG_CODEC_CONFIG) != 0) {
    // Codec-specific Data, 这里可以从ByteBuffer中获取csd参数
    // audioFormat.setByteBuffer("csd-0", mOutBuffer);
} else {
    // 处理数据
}
mAudioEncoder.releaseOutputBuffer(outputBufIndex, false);


顺序
1.mAudioInputBuffers = mAudioEncoder.getInputBuffers();
2.int inputBufIndex = mAudioEncoder.dequeueInputBuffer(1000);
3.mInputBuffer.clear();
4.mInputBuffer.put(bytes, 0, BUFFER_SIZE_IN_BYTES);
5.mAudioEncoder.queueInputBuffer(inputBufIndex, 0, BUFFER_SIZE_IN_BYTES, (1000000 * mEncodedSize / AUDIO_BYTE_PER_SAMPLE), 0);




通过getInputBuffers()得到的是输入缓存数组，通过index和输入缓存数组可以得到当前请求的输入缓存，
在使用之前要clear一下，避免之前的缓存数据影响当前数据：
mInputBuffer = mAudioInputBuffers[inputBufIndex];
mInputBuffer.clear();

接着就是把数据添加到输入缓存中，并调用queueInputBuffer(...)把缓存数据入队：

mInputBuffer.put(bytes, 0, BUFFER_SIZE_IN_BYTES);
mAudioEncoder.queueInputBuffer(inputBufIndex, 0, BUFFER_SIZE_IN_BYTES, (1000000 * mEncodedSize / AUDIO_BYTE_PER_SAMPLE), 0);

获取输出缓存和获取输入缓存类似，首先通过dequeueOutputBuffer(BufferInfo info, long timeoutUs)来请求一个输出缓存，这里需要传入一个BufferInfo对象，用于存储ByteBuffer的信息：

int outputBufIndex = mAudioEncoder.dequeueOutputBuffer(mOutBufferInfo, 1000);

然后通过返回的index得到输出缓存，并通过BufferInfo获取ByteBuffer的信息，通过BufferInfo我们可以得到当前数据是否Codec-specific Data：




queueInputBuffer和dequeueInputBuffer是一对方法，两个要在一起使用哦。
首先，这一对函数的应用场合是对输入的数据流进行编码或者解码处理的时候，
你会通过各种方法获得一个ByteBuffer的数组，这些数据就是准备处理的数据。
你要通过自己的方法找到你要处理的部分，
然后调用dequeueInputBuffer方法提取出要处理的部分（也就是一个ByteBuffer数据流），把这一部分放到缓存区。
接下来就是你自己对于这个数据流的处理了。
然后在处理完毕之后，一定要调用queueInputBuffer把这个ByteBuffer放回到队列中，这样才能正确释放缓存区。
对于输出的数据流，同样也有一对这样的函数，叫做queueOutputBuffer和dequeueOutputBuffer，作用类似哦。


我们先来看一下Android系统中解码器的命名，软解码器通常是以OMX.google开头的。
硬解码器通常是以OMX.[hardware_vendor]开头的，比如TI的解码器是以OMX.TI开头的。
当然还有一些不遵守这个命名规范的，不以OMX.开头的，那也会被认为是软解码器。


https://juejin.im/entry/582d0342d203090067f605f2



作者：何俊林
链接：https://www.zhihu.com/question/30922650/answer/120365394
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

- Surface: 处理被屏幕排序的原生的buffer，Android中的Surface就是一个用来画图形（graphics）或图像（image）的地方，
对于View及其子类，都是画在Surface上，各Surface对象通过Surfaceflinger合成到frameBuffer，
每个Surface都是双缓冲（实际上就是两个线程，一个渲染线程，一个UI更新线程），
它有一个backBuffer和一个frontBuffer，Surface中创建了Canvas对象，用来管理Surface绘图操作，
Canvas对应Bitmap，存储Surface中的内容。- SurfaceView: 这个可能经常被说起，
在Camera,MediaRecorder,MediaPlayer中用来显示图像的。SurfaceView是View的子类，
且实现了Parcelable接口且实现了Parcelable接口，其中内嵌了一个专门用于绘制的Surface，
SurfaceView可以控制这个Surface的格式和尺寸，以及Surface的绘制位置。
可以理解为Surface就是管理数据的地方，SurfaceView就是展示数据的地方。
- SurfaceHolder:顾名思义，一个管理SurfaceHolder的容器。SurfaceHolder是一个接口，
可理解为一个Surface的监听器。
通过回调方法addCallback（SurfaceHolder.Callback callback )监听Surface的创建 通过获取Surface中的Canvas对象，
并锁定之。所得到的Canvas对象 通过当修改Surface中的数据完成后，释放同步锁，并提交改变Surface的状态及图像，将新的图像数据进行展示。- 而最后综合：SurfaceView中调用getHolder方法，可以获得当前SurfaceView中的Surface对应的SurfaceHolder，SurfaceHolder开始对Surface进行管理操作。这里其实按MVC模式理解的话，可以更好理解。M:Surface(图像数据)，V:SurfaceView(图像展示)，C:SurfaceHolder(图像数据管理)。

synchronized 是java语言关键字，当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。synchronized 关键字，它包括两种用法：synchronized 方法和 synchronized 块。  

synchronized 块：通过 synchronized关键字来声明synchronized 块。语法如下： 
synchronized(syncObject) { 
//允许访问控制的代码 
} 
synchronized 块是这样一个代码块，其中的代码必须获得对象 syncObject （如前所述，可以是类实例或类）的锁方能执行，具体机

制同前所述。由于可以针对任意代码块，且可任意指定上锁的对象，故灵活性较高。 



handler通俗一点讲就是用来在各个进程之间发送数据的处理对象。在任何进程中，只要获得了另一个进程的handler则可以通过 handler.sendMessage(message)方法向那个进程发送数据。基于这个机制，我们在处理多线程的时候可以新建一个thread，这 个thread拥有UI线程中的一个handler。当thread处理完一些耗时的操作后通过传递过来的handler像ui线程发送数据，由UI线程 去更新界面。

在Android 中Handler和Message、Thread有着很密切的关系。
Handler 主要是负责Message的分发和处理。
但是这个Message从哪里来的呢？Message 由一个消息队列进行管理，而消息队列却由一个Looper进行管理。
Android系统中Looper负责管理线程的消息队列和消息循环，具体实现请参考Looper的源码。 


public void handleMessage (Message msg) 子类对象通过该方法接收信息

当应用程序启动时，Android首先会开启一个主线程 (也就是UI线程) , 主线程为管理界面中的UI控件，进行事件分发, 
比如说, 你要是点击一个 Button ,Android会分发事件到Button上，来响应你的操作。 
如果此时需要一个耗时的操作，例如: 联网读取数据，    
或者读取本地较大的一个文件的时候，你不能把这些操作放在主线程中，，如果你放在主线程中的话，界面会出现假死现象, 如果5秒钟还没有完成的话，，会收到Android系统的一个错误提示  "强制关闭".  这个时候我们需要把这些耗时的操作，放在一个子线程中,因为子线程涉及到UI更新，，Android主线程是线程不安全的，也就是说，更新UI只能在主线程中更新，子线程中操作是危险的. 这个时候，Handler就出现了.,来解决这个复杂的问题 ,    由于Handler运行在主线程中(UI线程中),  它与子线程可以通过Message对象来传递数据, 这个时候，Handler就承担着接受子线程传过来的(子线程用sedMessage()方法传弟)Message对象，(里面包含数据)  , 把这些消息放入主线程队列中，配合主线程进行更新UI。

handler通俗一点讲就是用来在各个进程之间发送数据的处理对象。在任何进程中，只要获得了另一个进程的handler则可以通过 handler.sendMessage(message)方法向那个进程发送数据。基于这个机制，我们在处理多线程的时候可以新建一个thread，这 个thread拥有UI线程中的一个handler。当thread处理完一些耗时的操作后通过传递过来的handler像ui线程发送数据，由UI线程 去更新界面。

我们创建的Service、Activity以及Broadcast均是一个主线程处理，这里我们可以理解为UI线程。但是在操作一些耗时操作时，比如I/O读写的大文件读写，数据库操作以及网络下载需要很长时间，为了不阻塞用户界面，出现ANR的响应提示窗口，这个时候我们可以考虑使用Thread线程来解决。

Android可有两种方式实现多线程，一种是继承Thread类，一种是实现Runnable接口；前者只要继承了Thread类同时覆写了本类中的run()方法就可以实现多线程操作了，但是Java中一个类只能继承一个父类，这是这种方式的局限性，后者只需要实现一个接口而已，Java中可以实现多个接口。

实现Runnable接口。

      Runnable只是一个接口，它里面只有一个run()方法，没有start()方法，
	  
public interface Runnable{    
public void run();    
}   

      所以，即使实现了Runnable接口，那也无法启动线程，必须依托其他类。
      而Thread类，有一个构造方法，参数是Runnable对象，也就是说可以通过Thread类来启动Runnable实现的多线程。

[java] view plain copy
public Thread(Runnable target) {  
     init(null, target, "Thread-" + nextThreadNum(), 0);  
 }  
      所以，实现Runnable接口后，需要使用Thread类来启动

“猪八戒吃西瓜”这样一件事情。

                         面向过程的思维：吃（猪八戒,西瓜）;     面向对象的思维：猪八戒.吃（西瓜）；

	  
	  
	  
	  
	  Android NDK 是在SDK前面又加上了“原生”二字，即Native Development Kit，因此又被Google称为“NDK”。
	  
	  
	  
	  
MPEG-4	Decoder-specific information from ESDS*	Not Used	Not Used
H.264 AVC	SPS (Sequence Parameter Sets*)	PPS (Picture Parameter Sets*)	  


h264的功能分为两层，视频编码层（VCL）和网络提取层（NAL）。H.264 的编码视频序列包括一系列的NAL 单元，每个NAL 单元包含一个RBSP。一个原始的H.264 NALU 单元常由 [StartCode] [NALU Header] [NALU Payload] 三部分组成，其中 Start Code 用于标示这是一个NALU 单元的开始，必须是"00 00 00 01" 或"00 00 01"。
http://blog.csdn.net/alien75/article/details/38399399

带有开始码的H.264视频一般是用于无线发射、有线广播或者HD-DVD中的。这些数据流的开始都有一个开始码：0x000001 或者 0x00000001.
没有开始码的H.264视频主要是存储在MP4格式的文件中的。它的数据流的开始是1、2或者4个字节表示长度数据。
原文中的"NALU"简单说是H.264格式中的最基本的单元，是一个数据包。
通过VLC播放器，可以查看到具体的格式。打开视频后，通过菜单【工具】/【编解码信息】可以查看到【编解码器】具体格式，举例如下，编解码器信息：
编码: H264 – MPEG-4 AVC (part 10) (avc1)
编码: H264 – MPEG-4 AVC (part 10) (h264)



序列参数集（SPS）、图像参数集（PPS）、增强信息（SEI）、条带（Slice）


总的来说H264的码流的打包方式有两种,一种为annex-b byte stream format的格式，这个是绝大部分编码器的默认输出格式，就是每个帧的开头的3~4个字节是H264的start_code,0x00000001或者0x000001。
另一种是原始的NAL打包格式，就是开始的若干字节（1，2，4字节）是NAL的长度，而不是start_code,此时必须借助某个全局的数据来获得编码器的profile,level,PPS,SPS等信息才可以解码。

SODB        数据比特串 ----＞最原始的编码数据，即VCL数据；

RBSP　     原始字节序列载荷 ----＞在SODB的后面填加了结尾比特（RBSP trailing bits　一个bit“1”）若干比特“0”,以便字节对齐；

EBSP　     扩展字节序列载荷 ---- > 在RBSP基础上填加了仿校验字节（0X03）它的原因是：　在NALU加到Annexb上时，需要添加每组NALU之前的开始码StartCodePrefix,如果该NALU对应的slice为一帧的开始则用4位字节表示，ox00000001,否则用3位字节表示ox000001（是一帧的一部分）。另外，为了使NALU主体中不包括与开始码相冲突的，在编码时，每遇到两个字节连续为0，就插入一个字节的0x03。解码时将0x03去掉。也称为脱壳操作。
H264/AVC 的分层结构


RBSP

RBSP数据是下表中的一种


RBSP类型	所写	描述
参数集	PS	序列的全局信息，如图像尺寸，视频格式等
增强信息	SEI	视频序列解码的增强信息
图像界定符	PD	视频图像的边界
编码片	SLICE	编码片的头信息和数据
数据分割	 	DP片层的数据，用于错误恢复解码
序列结束符	 	表明一个序列的结束，下一个图像为IDR图像
流结束符	 	表明该流中已没有图像
填充数据	 	亚元数据，用于填充字节

http://blog.csdn.net/mincheat/article/details/48713047

参数集:包括序列参数集 SPS  和图像参数集 PPS
       SPS 包含的是针对一连续编码视频序列的参数，如标识符 seq_parameter_set_id、帧数及 POC 的约束、参考帧数目、解码图像尺寸和帧场编码模式选择标识等等。
       PPS对应的是一个序列中某一幅图像或者某几幅图像，

       其参数如标识符 pic_parameter_set_id、可选的 seq_parameter_set_id、熵编码模式选择标识、片组数目、初始量化参数和去方块滤波系数调整标识等等。
	   
      SEI(Supplemental Enhancement Information):辅助增强信息。这里面可以存放一些影片简介，版权信息或者作者自己添加的一些信息。
	   
Type: 5个比特.
  nal_unit_type. 这个NALU单元的类型.简述如下:

  0     没有定义
  1-23  NAL单元  单个 NAL 单元包
  24    STAP-A   单一时间的组合包
  25    STAP-B   单一时间的组合包
  26    MTAP16   多个时间的组合包
  27    MTAP24   多个时间的组合包
  28    FU-A     分片的单元
  29    FU-B     分片的单元
  30-31 没有定义

h264仅用1-23,24以后的用在RTP H264负载类型头中	   
	   
 [00 00 00 01 67 42 A0 1E 23 56 0E 2F … ]

  这是一个序列参数集 NAL 单元. [00 00 00 01] 是四个字节的开始码, 67 是 NALU 头, 42 开始的数据是 NALU 内容.

  封装成 RTP 包将如下:

  [ RTP Header ] [ 67 42 A0 1E 23 56 0E 2F ]

  即只要去掉 4 个字节的开始码就可以了.

如有一个 H.264 的 NALU 是这样的:

  [00 00 00 01 67 42 A0 1E 23 56 0E 2F … ]

  [00 00 00 01 68 42 B0 12 58 6A D4 FF … ]

  封装成 RTP 包将如下:

  [ RTP Header ] [78 (STAP-A头，占用1个字节)] [第一个NALU长度 (占用两个字节)] [ 67 42 A0 1E 23 56 0E 2F ] [第二个NALU长度 (占用两个字节)] [68 42 B0 12 58 6A D4 FF … ]  
	   
	   
当NALU的长度超过MTU时,就必须对NALU单元进行分片封包.也称为Fragmentation Units(FUs).	   

http://blog.csdn.net/yibu_refresh/article/details/52829643

http://blog.csdn.net/chen495810242/article/details/39207305
http://blog.csdn.net/fishmai/article/details/53676194


RTSP(Real-Time Stream Protocol )是一种基于文本的应用层协议,直白的讲客户端与服务器建立连接并从服务器上接收流，服务器上的流可以是采集的，文件，等等。
http://blog.csdn.net/smilestone_322/article/details/17892967


       0                   1                   2                   3
       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |V=2|P|X|  CC   |M|     PT      |       sequence number         |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                           timestamp                           |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |           synchronization source (SSRC) identifier            |
      +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+
      |            contributing source (CSRC) identifiers             |
      |                             ....                              |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

                       图 1.  RTP 头。
					   
					   
					   
					   
					   
http://blog.csdn.net/WificamSDK7/article/details/51148998					   


http://blog.csdn.net/true100/article/details/53992939
http://blog.csdn.net/zgcqflqinhao/article/details/53257358

h264是一种视频编码格式它是一种很高明的视频算法，
视频播放的时候，差不多每秒会播24帧，如果以一部1280*720的2小时的电影为例，
差不多会有148GB大小，显然这太庞大了，而采用h264编码，它会首先传一个关键帧（I 帧），
然后比较下一帧跟上一帧之间的差异，将这两帧的差异作为一个补偿帧(P/B帧)，这样的话，
只需要传补偿帧就可以进行画面的更新，除非整个场景的切换，
才会又传一个关键帧，不然的话只传一个补偿帧，数据量还是很小的，所以才把一部电影压缩到只有1-2GB这么大。


http://blog.csdn.net/zgcqflqinhao/article/details/53257358

https://github.com/ldm520/ANDROID_MEDIACODEC_RTSP_H264

00 00 00 01 67    (SPS)

00 00 00 01 68    (PPS)

00 00 00 01 65    ( IDR 帧)

00 00 00 01 61    (P帧)


key frame need to add sps pps



第一帧是00 00 00 01 67 42 C0 28 DA 01 E0 08 9F 96 10 00 00 03 00 10 00 00 03 01 48 F1 83 2A
第二帧是00 00 00 01 68 CE 3C 80
第三帧是00 00 01 06 05 FF FF 5D DC 45 E9 BD E6 D9 48 B7 96 2C D8 20 D9 23 EE EF ..

帧类型有：

NAL_SLICE = 1 非关键帧
NAL_SLICE_DPA = 2
NAL_SLICE_DPB = 3
NAL_SLICE_DPC =4
NAL_SLICE_IDR =5 关键帧
NAL_SEI = 6
NAL_SPS = 7 SPS帧
NAL_PPS = 8 PPS帧
NAL_AUD = 9
NAL_FILLER = 12

SPS 对于H264而言，就是编码后的第一帧，如果是读取的H264文件，就是第一个帧界定符和第二个帧界定符之间的数据的长度是4

PPS 就是编码后的第二帧，如果是读取的H264文件，就是第二帧界定符和第三帧界定符中间的数据长度不固定。

作者：zjunchao
链接：https://www.jianshu.com/p/d28e25ae339e
來源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

2.回绕缓冲区
  buffer.flip();
  这个方法用来将缓冲区准备为数据传出状态,执行以上方法后,输出通道会从数据的开头而不是末尾开始.回绕保持缓冲区中的数据不变,只是准备写入而不是读取.
  
  
put(byte b)	相对写，向position的位置写入一个byte，并将postion+1，为下次读写作准备
put(int index, byte b)	绝对写，向byteBuffer底层的bytes中下标为index的位置插入byte b，不改变position
put(ByteBuffer src)	用相对写，把src中可读的部分（也就是position到limit）写入此byteBuffer
put(byte[] src, int offset, int length)	从src数组中的offset到offset+length区域读取数据并使用相对写写入此byteBuffer

http://blog.csdn.net/bzlj2912009596/article/details/75581675

  buffer.flip();
  这个方法用来将缓冲区准备为数据传出状态,执行以上方法后,输出通道会从数据的开头而不是末尾开始.回绕保持缓冲区中的数据不变,只是准备写入而不是读取.

  
     capacity：缓冲区的容量；


　　limit：缓冲区还有多少数据能够取出或者缓冲区还有多少容量用于存放数据；


　　position：相当于一个游标（cursor），记录我们从哪里开始写数据，从哪里开始读数据。

 

  三者关系：capacity代表了Buffer的容量是不变的，limit与position的差总是表示Buffer总可以读的数据，或者Buffer中可以写数据的容量。还有position总是小于等于limit，limit总是

 

小于等于capacity。

