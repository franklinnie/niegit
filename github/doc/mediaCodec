MediaCodec是一个Android原生的编解码器。
简单的来说，MediaCodec可以把摄像头采集的数据流编码为H264格式，这个过程是压缩过程。也可以把H264格式解码在surface类的控件上显示。

我们先来看一下Android系统中解码器的命名，软解码器通常是以OMX.google开头的。硬解码器通常是以OMX.[hardware_vendor]开头的，比如TI的解码器是以OMX.TI开头的。当然还有一些不遵守这个命名规范的，不以OMX.开头的，那也会被认为是软解码器。

从广义上讲，编解码器就是处理输入数据来产生输出数据。MediaCode采用异步方式处理数据，并且使用了一组输入输出缓存（input and output buffers）。简单来讲，你请求或接收到一个空的输入缓存（input buffer），向其中填充满数据并将它传递给编解码器处理。编解码器处理完这些数据并将处理结果输出至一个空的输出缓存（output buffer）中。
最终，你请求或接收到一个填充了结果数据的输出缓存（output buffer），使用完其中的数据，并将其释放给编解码器再次使用。

getInputBuffers：获取需要编码数据的输入流队列，返回的是一个ByteBuffer数组 
queueInputBuffer：输入流入队列 
dequeueInputBuffer：从输入流队列中取数据进行编码操作 
getOutputBuffers：获取编解码之后的数据输出流队列，返回的是一个ByteBuffer数组 
dequeueOutputBuffer：从输出队列中取出编码操作之后的数据 
releaseOutputBuffer：处理完成，释放ByteBuffer数据

MediaCodec的使用遵循一个基本模式：

    1.创建和配置MediaCodec对象

    2.进行以下循环：
        如果一个输入缓冲区准备好：
        读取部分数据，复制到缓冲区
        如果一个输出缓冲区准备好：
        复制到缓冲区
    3.销毁MediaCodec对象

http://blog.csdn.net/hejjunlin/article/details/53386117


MediaCodec类是用来为低级别的媒体编码和解码的媒体编解码器提供访问。您可以实例化一个MediaCodec类通过调用createEncoderByType()方法来进行对媒体文件进行编码或者调用createDecoderByType()来对媒体文件进行解码。每一个方法都要采取一个MIME类型为你想要编码或者解码的媒体文件类型，例如“video/3gpp”或者“audio/vorbis”。

在MediaCodec实例创建之后，你可以调用configure()方法来指定例如媒体格式或者是否对内容加密的属性。

无论你是对你的媒体文件进行编码还是解码，在你创建MediaCodec实例后的其余进程都是一样的。首先通过getInputBuffers()的方法获得输入ByteBuffer对象的一个数组然后再通过getOutputBuffers()方法来获得一个输出的ByteBuffer的对象数组。

当你准备好进行编码或者解码的时候，调用dequeueInputBuffer()方法来获得这个用来作为媒体文件源码的ByteBuffer（从输入的buffers的数组中）的索引位置。在你使用带有媒体文件源码的ByteBuffer之后，通过调用queueInputBuffer()方法来释放缓存区的所有权。

对输出缓存区也是一样的，调用dequeueOutputBuffer()方法来获得你接收到结果的ByteBuffer的索引位置。在你从ByteBuffer读出输出之后，通过调用releaseOutputBuffer()方法来释放所有权。

MPEG-4由一系列的子标准组成，被称为部，包括以下的部分。对于媒体编解码，重点关注Part2,Part 3, Part 10。

第一部（ISO/IEC 14496-1）：系统

　　描述视訊和音訊的同步以及混合方式（Multiplexing，简写为MUX）。定义了 MP4 容器格式, 支持类似 DVD 菜单这样的直观和互动特性等。

第二部（ISO/IEC 14496-２）：视频

　　定义了一个对各种视觉信息（包括视訊、静止纹理、计算机合成图形等等）的编解码器。对视訊部分来说，众多”Profiles”中很常用的一种是Advanced SimpleProfile (ASP)，例如XviD编码就 属于MPEG-4Part 2。包括 3ivx, DivX4/Project Mayo, DivX 5, Envivio,ffmpeg/ffds, mpegable, Nero Digital, QuickTime, Sorenson, XviD 等常见的视频格式, 需要注意的是 Divx 3.11, MS MPEG-4, RV9/10, VP6,WMV9 并不属于标准的 MPEG-4 标准。

第三部（ISO/IEC 14496-３）：音频

　　定义了一个对各种音訊信号进行编码的编解码器的集合。包括高级音訊编码（Advanced Audio Coding，缩写为AAC） 的若干变形和其他一些音频／语音编码工具。即 AAC 音频标准, 包括 LCAAC, HE AAC 等, 支持 5.1 声道编码, 可以用更低的码率实现更好的效果 (相对于 MP3, OGG 等) 。

第四部（ISO/IEC 14496-4）：一致性

　　定义了对本标准其他的部分进行一致性测试的程序。

第五部（ISO/IEC 14496-5）：参考软件

　　提供了用于演示功能和说明本标准其他部分功能的软件。

第六部（ISO/IEC 14496-6）：多媒体传输集成框架

　　即DMIF：Delivery Multimedia IntegrationFramework

第七部（ISO/IEC 14496-7）：优化的参考软件

　　提供了对实现进行优化的例子（这裡的实现指的是第五部分）。

第八部（ISO/IEC 14496-8）：在IP网络上传输

　　定义了在IP网络上传输MPEG-4内容的方式。

第九部（ISO/IEC 14496-9）：参考硬件

　　提供了用于演示怎样在硬件上实现本标准其他部分功能的硬件设计方案。

第十部（ISO/IEC 14496-10）：进阶视频编码，也即ITU H.264，常写为H.264／AVC

　　或称高级视频编码（Advanced Video Coding，缩写为AVC）：定义了一个视频编解码器（codec），AVC和XviD都属于MPEG-4编码，但由于AVC属于MPEG-4Part 10，在技术特性上比属于MPEG-4 Part2的XviD要先进。另外从技术上讲，它和ITU-T H.264标准是一致的，故全称为MPEG-4 AVC/H.264。

第十一部（ISO/IEC 14496-11）：场景描述和应用引擎

　　可用于多种profile（包括2D和3D版本）的互交互媒体。修订了MPEG-4 Part 1:2001以及Part1的两个修订方案。它定义了应用引擎（交付，生命周期，格式，可下载Java字节代码应用程序的行为），二进制场景格式 （BIFS：Binary Format for Scene），可扩展MPEG-4文本格式（一种使用XML描述MPEG-4多媒体内容的文本格式）系统level表述。也就是MPEG-4 Part21中的BIFS，XMT，MPEG-J。

第十二部（ISO/IEC 14496-12）：基于ISO的媒体文件格式

　　定义了一个存储媒体内容的文件格式。

第十三部（ISO/IEC 14496-13）：IP

　　知识产权管理和保护（IPMP for Intellectual Property Management and Protection）拓展。

第十四部（ISO/IEC 14496-14）：MPEG-4文件格式

　　定义了基于第十二部分的用于存储MPEG-4内容的視訊檔案格式。

第十五部（ISO/IEC 14496-15）：AVC文件格式

　　定义了基于第十二部分的用于存储第十部分的视频内容的文件格式。

第十六部（ISO/IEC 14496-16）：动画框架扩展

　　动画框架扩展（AFX : Animation Framework eXtension）。

第十七部（ISO/IEC 14496-17）：同步文本字幕格式

　　尚未完成－2005年1月达成”最终委员会草案”，FCD: Final Committee Draft。

第十八部（ISO/IEC 14496-18）：字体压缩和流式传输（针对公开字体格式）。

第十九部（ISO/IEC 14496-19）：综合用材质流（Synthesized TextureStream）。

第二十部（ISO/IEC 14496-20）：简单场景表示

　　LASeR for Lightweight Scene Representation，尚未完成－2005年1月达成”最终委员会草案”，FCD for Final Committee Draft。

第二十一部（ISO/IEC 14496-21）：用于描绘（Rendering）的MPEG-J拓展

　　尚未完成－2005年1月达成“委员会草案”，CD for Committee Draft）。

Profile和Level 

http://blog.csdn.net/ouyang_peng/article/details/48752143
